{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transforms=transform):\n",
    "        self.data = []\n",
    "        rootdir = 'train'\n",
    "        self.transforms = transform\n",
    "        for subdir, dirs, files in os.walk('train/NORMAL'):\n",
    "            for file in files:\n",
    "                filepath = subdir + os.sep + file\n",
    "                self.data.append([self.transforms(Image.open(filepath).convert(\"RGB\")), 0])\n",
    "        for subdir, dirs, files in os.walk('train/PNEUMONIA'):\n",
    "            for file in files:\n",
    "                filepath = subdir + os.sep + file\n",
    "                self.data.append([self.transforms(Image.open(filepath).convert(\"RGB\")), 1])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "traindata = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Valdata(torch.utils.data.Dataset):\n",
    "    def __init__(self, transforms=transform):\n",
    "        self.data = []\n",
    "        rootdir = 'val'\n",
    "        self.transforms = transform\n",
    "        for subdir, dirs, files in os.walk('val/NORMAL'):\n",
    "            for file in files:\n",
    "                filepath = subdir + os.sep + file\n",
    "                self.data.append([self.transforms(Image.open(filepath).convert(\"RGB\")), 0])\n",
    "        for subdir, dirs, files in os.walk('val/PNEUMONIA'):\n",
    "            for file in files:\n",
    "                filepath = subdir + os.sep + file\n",
    "                self.data.append([self.transforms(Image.open(filepath).convert(\"RGB\")), 1])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "valdata = Valdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Testdata(torch.utils.data.Dataset):\n",
    "    def __init__(self, transforms=transform):\n",
    "        self.data = []\n",
    "        rootdir = 'test'\n",
    "        self.transforms = transform\n",
    "        for subdir, dirs, files in os.walk('test/NORMAL'):\n",
    "            for file in files:\n",
    "                filepath = subdir + os.sep + file\n",
    "                self.data.append([self.transforms(Image.open(filepath).convert(\"RGB\")), 0])\n",
    "        for subdir, dirs, files in os.walk('test/PNEUMONIA'):\n",
    "            for file in files:\n",
    "                filepath = subdir + os.sep + file\n",
    "                self.data.append([self.transforms(Image.open(filepath).convert(\"RGB\")), 1])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "testdata = Testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=32, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valdata, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /home/gpu-station/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ee3ab8c77e4339bc637497041167c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet152(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1000, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "mynet = Net()\n",
    "net = nn.Sequential(model, mynet)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 elapsed -----> loss:0.331467, val_loss:1.899046\n",
      "Epoch 1 elapsed -----> loss:0.320871, val_loss:1.200640\n",
      "Epoch 2 elapsed -----> loss:0.315729, val_loss:1.092165\n",
      "Epoch 3 elapsed -----> loss:0.311224, val_loss:1.381870\n",
      "Epoch 4 elapsed -----> loss:0.305054, val_loss:1.805350\n",
      "Epoch 5 elapsed -----> loss:0.313120, val_loss:2.165716\n",
      "Epoch 6 elapsed -----> loss:0.312695, val_loss:1.942808\n",
      "Epoch 7 elapsed -----> loss:0.303045, val_loss:1.462704\n",
      "Epoch 8 elapsed -----> loss:0.304188, val_loss:1.852155\n",
      "Epoch 9 elapsed -----> loss:0.290924, val_loss:1.610152\n",
      "Epoch 10 elapsed -----> loss:0.289441, val_loss:1.434570\n",
      "Epoch 11 elapsed -----> loss:0.286071, val_loss:1.532824\n",
      "Epoch 12 elapsed -----> loss:0.291996, val_loss:1.297253\n",
      "Epoch 13 elapsed -----> loss:0.283306, val_loss:1.535838\n",
      "Epoch 14 elapsed -----> loss:0.284575, val_loss:1.428553\n",
      "Epoch 15 elapsed -----> loss:0.288662, val_loss:1.492237\n",
      "Epoch 16 elapsed -----> loss:0.286774, val_loss:1.465596\n",
      "Epoch 17 elapsed -----> loss:0.279363, val_loss:1.708635\n",
      "Epoch 18 elapsed -----> loss:0.282275, val_loss:1.611121\n",
      "Epoch 19 elapsed -----> loss:0.281905, val_loss:1.336068\n",
      "CPU times: user 5min 58s, sys: 340 ms, total: 5min 59s\n",
      "Wall time: 5min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "net.to(device)\n",
    "for epoch in range(20):\n",
    "    running_loss = 0\n",
    "    net.train()\n",
    "    for images, labels in trainloader:\n",
    "        images = images.to(device); labels = labels.to(device)\n",
    "        outputs = net(images); labels = labels.float()\n",
    "        outputs = outputs.reshape(labels.shape)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "    scheduler.step()\n",
    "    net.eval()\n",
    "    val_loss = 0\n",
    "    for images, labels in valloader:\n",
    "        images = images.to(device); labels = labels.to(device)\n",
    "        outputs = net(images); labels = labels.float()\n",
    "        outputs = outputs.reshape(labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss+=loss.item()\n",
    "    print(\"Epoch {} elapsed -----> loss:{:5f}, val_loss:{:5f}\".format(epoch, running_loss/len(trainloader), val_loss/len(valloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.01 s, sys: 15.8 ms, total: 8.03 s\n",
      "Wall time: 8.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_hat = []\n",
    "y = []\n",
    "loss_on_test = 0\n",
    "for images, labels in testloader:\n",
    "    images = images.to(device); labels = labels.to(device)\n",
    "    outputs = net(images); labels = labels.float()\n",
    "    outputs = outputs.reshape(labels.shape)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss_on_test += loss.item()\n",
    "    y.append(labels.item())\n",
    "    y_hat.append((nn.Sigmoid()(outputs)).item())\n",
    "assert len(y_hat)==len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.array(y_hat); y = np.array(y)\n",
    "y_hat[y_hat<=0.5] = 0; y_hat[y_hat>0.5]=1\n",
    "accuracy_score = np.mean(np.absolute(y_hat - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14903846153846154\n",
      "0.5305528369661624\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score)\n",
    "print(loss_on_test/len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
